{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e790f51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Head:\n",
      "   BldgType CentralAir  SalePrice\n",
      "0     1Fam          Y     215000\n",
      "1     1Fam          Y     105000\n",
      "2     1Fam          Y     172000\n",
      "3     1Fam          Y     244000\n",
      "4     1Fam          Y     189900\n",
      "\n",
      "Shape: (2930, 3)\n",
      "\n",
      "Columns: Index(['BldgType', 'CentralAir', 'SalePrice'], dtype='object')\n",
      "\n",
      "Data Types:\n",
      " BldgType      object\n",
      "CentralAir    object\n",
      "SalePrice      int64\n",
      "dtype: object\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count  Dtype \n",
      "---  ------      --------------  ----- \n",
      " 0   BldgType    2930 non-null   object\n",
      " 1   CentralAir  2930 non-null   object\n",
      " 2   SalePrice   2930 non-null   int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 68.8+ KB\n",
      "\n",
      "Info:\n",
      " None\n",
      "\n",
      "Value Counts:\n",
      " SalePrice\n",
      "135000    34\n",
      "140000    33\n",
      "130000    29\n",
      "155000    28\n",
      "145000    26\n",
      "          ..\n",
      "219990     1\n",
      "159895     1\n",
      "187687     1\n",
      "217300     1\n",
      "150900     1\n",
      "Name: count, Length: 1032, dtype: int64\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "at least one array or dtype is required",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(X, y, test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.25\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n\u001b[0;32m     23\u001b[0m model \u001b[38;5;241m=\u001b[39m LinearRegression()\n\u001b[1;32m---> 24\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n\u001b[0;32m     25\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(X_test)\n\u001b[0;32m     26\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y_test, y_pred)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_base.py:678\u001b[0m, in \u001b[0;36mLinearRegression.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    674\u001b[0m n_jobs_ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs\n\u001b[0;32m    676\u001b[0m accept_sparse \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpositive \u001b[38;5;28;01melse\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcsc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcoo\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 678\u001b[0m X, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_data(\n\u001b[0;32m    679\u001b[0m     X, y, accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse, y_numeric\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, multi_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    680\u001b[0m )\n\u001b[0;32m    682\u001b[0m has_sw \u001b[38;5;241m=\u001b[39m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_sw:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:621\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001b[0m\n\u001b[0;32m    619\u001b[0m         y \u001b[38;5;241m=\u001b[39m check_array(y, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_y_params)\n\u001b[0;32m    620\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 621\u001b[0m         X, y \u001b[38;5;241m=\u001b[39m check_X_y(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcheck_params)\n\u001b[0;32m    622\u001b[0m     out \u001b[38;5;241m=\u001b[39m X, y\n\u001b[0;32m    624\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mensure_2d\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1147\u001b[0m, in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m   1142\u001b[0m         estimator_name \u001b[38;5;241m=\u001b[39m _check_estimator_name(estimator)\n\u001b[0;32m   1143\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1144\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m requires y to be passed, but the target y is None\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1145\u001b[0m     )\n\u001b[1;32m-> 1147\u001b[0m X \u001b[38;5;241m=\u001b[39m check_array(\n\u001b[0;32m   1148\u001b[0m     X,\n\u001b[0;32m   1149\u001b[0m     accept_sparse\u001b[38;5;241m=\u001b[39maccept_sparse,\n\u001b[0;32m   1150\u001b[0m     accept_large_sparse\u001b[38;5;241m=\u001b[39maccept_large_sparse,\n\u001b[0;32m   1151\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[0;32m   1152\u001b[0m     order\u001b[38;5;241m=\u001b[39morder,\n\u001b[0;32m   1153\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   1154\u001b[0m     force_all_finite\u001b[38;5;241m=\u001b[39mforce_all_finite,\n\u001b[0;32m   1155\u001b[0m     ensure_2d\u001b[38;5;241m=\u001b[39mensure_2d,\n\u001b[0;32m   1156\u001b[0m     allow_nd\u001b[38;5;241m=\u001b[39mallow_nd,\n\u001b[0;32m   1157\u001b[0m     ensure_min_samples\u001b[38;5;241m=\u001b[39mensure_min_samples,\n\u001b[0;32m   1158\u001b[0m     ensure_min_features\u001b[38;5;241m=\u001b[39mensure_min_features,\n\u001b[0;32m   1159\u001b[0m     estimator\u001b[38;5;241m=\u001b[39mestimator,\n\u001b[0;32m   1160\u001b[0m     input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1161\u001b[0m )\n\u001b[0;32m   1163\u001b[0m y \u001b[38;5;241m=\u001b[39m _check_y(y, multi_output\u001b[38;5;241m=\u001b[39mmulti_output, y_numeric\u001b[38;5;241m=\u001b[39my_numeric, estimator\u001b[38;5;241m=\u001b[39mestimator)\n\u001b[0;32m   1165\u001b[0m check_consistent_length(X, y)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:797\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    793\u001b[0m pandas_requires_conversion \u001b[38;5;241m=\u001b[39m \u001b[38;5;28many\u001b[39m(\n\u001b[0;32m    794\u001b[0m     _pandas_dtype_needs_early_conversion(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m dtypes_orig\n\u001b[0;32m    795\u001b[0m )\n\u001b[0;32m    796\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mall\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(dtype_iter, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;28;01mfor\u001b[39;00m dtype_iter \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[1;32m--> 797\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mresult_type(\u001b[38;5;241m*\u001b[39mdtypes_orig)\n\u001b[0;32m    798\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m pandas_requires_conversion \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(d \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m dtypes_orig):\n\u001b[0;32m    799\u001b[0m     \u001b[38;5;66;03m# Force object if any of the dtypes is an object\u001b[39;00m\n\u001b[0;32m    800\u001b[0m     dtype_orig \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mobject\u001b[39m\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mresult_type\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: at least one array or dtype is required"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression, SGDRegressor, RidgeCV, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Step 1: Import dataset\n",
    "df = pd.read_csv(\"ames_house.csv\")\n",
    "print(\"Head:\\n\", df.head())\n",
    "print(\"\\nShape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns)\n",
    "print(\"\\nData Types:\\n\", df.dtypes)\n",
    "print(\"\\nInfo:\\n\", df.info())\n",
    "print(\"\\nValue Counts:\\n\", df[\"SalePrice\"].value_counts())\n",
    "\n",
    "# Step 2: Predict Sale Price without Categorical features\n",
    "X = df.drop(['BldgType', 'CentralAir', 'SalePrice'], axis=1)\n",
    "y = df['SalePrice']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print(\"\\nMean Squared Error (without Categorical features):\", mse)\n",
    "\n",
    "# Step 3: Create Scatter Plot\n",
    "plt.scatter(y_test, y_pred)\n",
    "plt.xlabel(\"Actual Sale Price\")\n",
    "plt.ylabel(\"Predicted Sale Price\")\n",
    "plt.title(\"Scatter Plot between y_test and y_pred\")\n",
    "plt.show()\n",
    "\n",
    "# Step 4: Encode Categorical columns\n",
    "df_encoded = pd.get_dummies(df, columns=['BldgType', 'CentralAir'])\n",
    "\n",
    "# Step 5: Predict Sale Price with Categorical features\n",
    "X_encoded = df_encoded.drop('SalePrice', axis=1)\n",
    "y_encoded = df_encoded['SalePrice']\n",
    "X_train_encoded, X_test_encoded, y_train_encoded, y_test_encoded = train_test_split(X_encoded, y_encoded, test_size=0.25, random_state=42)\n",
    "\n",
    "model_encoded = LinearRegression()\n",
    "model_encoded.fit(X_train_encoded, y_train_encoded)\n",
    "y_pred_encoded = model_encoded.predict(X_test_encoded)\n",
    "mse_encoded = mean_squared_error(y_test_encoded, y_pred_encoded)\n",
    "print(\"\\nMean Squared Error (with Categorical features):\", mse_encoded)\n",
    "\n",
    "# Step 6: Normalize using Standard Scaler and Predict Sale Price\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_encoded)\n",
    "X_test_scaled = scaler.transform(X_test_encoded)\n",
    "\n",
    "model_scaled = LinearRegression()\n",
    "model_scaled.fit(X_train_scaled, y_train_encoded)\n",
    "y_pred_scaled = model_scaled.predict(X_test_scaled)\n",
    "mse_scaled = mean_squared_error(y_test_encoded, y_pred_scaled)\n",
    "print(\"\\nMean Squared Error (Standard Scaler):\", mse_scaled)\n",
    "\n",
    "# Step 7: Normalize using MinMaxScaler and Predict Sale Price\n",
    "minmax_scaler = MinMaxScaler()\n",
    "X_train_minmax = minmax_scaler.fit_transform(X_train_encoded)\n",
    "X_test_minmax = minmax_scaler.transform(X_test_encoded)\n",
    "\n",
    "model_minmax = LinearRegression()\n",
    "model_minmax.fit(X_train_minmax, y_train_encoded)\n",
    "y_pred_minmax = model_minmax.predict(X_test_minmax)\n",
    "mse_minmax = mean_squared_error(y_test_encoded, y_pred_minmax)\n",
    "print(\"\\nMean Squared Error (MinMax Scaler):\", mse_minmax)\n",
    "\n",
    "# Step 8: Predict using SGD Regressor\n",
    "sgd_scaler = StandardScaler()\n",
    "X_train_sgd = sgd_scaler.fit_transform(X_train_encoded)\n",
    "X_test_sgd = sgd_scaler.transform(X_test_encoded)\n",
    "\n",
    "sgd_model = SGDRegressor()\n",
    "sgd_model.fit(X_train_sgd, y_train_encoded)\n",
    "y_pred_sgd = sgd_model.predict(X_test_sgd)\n",
    "mse_sgd = mean_squared_error(y_test_encoded, y_pred_sgd)\n",
    "print(\"\\nMean Squared Error (SGD Regressor):\", mse_sgd)\n",
    "\n",
    "# Step 9: Predict using Ridge Regression\n",
    "ridge_model = RidgeCV()\n",
    "ridge_model.fit(X_train_sgd, y_train_encoded)\n",
    "y_pred_ridge = ridge_model.predict(X_test_sgd)\n",
    "mse_ridge = mean_squared_error(y_test_encoded, y_pred_ridge)\n",
    "print(\"\\nMean Squared Error (Ridge Regression):\", mse_ridge)\n",
    "\n",
    "# Step 10: Predict using Lasso Regression\n",
    "lasso_model = LassoCV()\n",
    "lasso_model.fit(X_train_sgd, y_train_encoded)\n",
    "y_pred_lasso = lasso_model.predict(X_test_sgd)\n",
    "mse_lasso = mean_squared_error(y_test_encoded, y_pred_lasso)\n",
    "print(\"\\nMean Squared Error (Lasso Regression):\", mse_lasso)\n",
    "\n",
    "# Step 11: RMSE\n",
    "rmse_no_encoding = np.sqrt(mse)\n",
    "rmse_encoding = np.sqrt(mse_encoded)\n",
    "rmse_standard_scaled = np.sqrt(mse_scaled)\n",
    "rmse_minmax_scaled = np.sqrt(mse_minmax)\n",
    "rmse_sgd = np.sqrt(mse_sgd)\n",
    "rmse_ridge = np.sqrt(mse_ridge)\n",
    "rmse_lasso = np.sqrt(mse_lasso)\n",
    "\n",
    "print(\"\\nRMSE without one hot encoding:\", rmse_no_encoding)\n",
    "print(\"RMSE with One hot encoding:\", rmse_encoding)\n",
    "print(\"RMSE with OHE and Standard Scaling:\", rmse_standard_scaled)\n",
    "print(\"RMSE with OHE and MinMax Scaling:\", rmse_minmax_scaled)\n",
    "print(\"RMSE of SGDRegressor with OHE and Standard Scaler:\", rmse_sgd)\n",
    "print(\"RMSE of RidgeCV with OHE and Standard Scaler:\", rmse_ridge)\n",
    "print(\"RMSE of LassoCV with OHE and Standard Scaler:\", rmse_lasso)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beba0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
